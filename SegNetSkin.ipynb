{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/hashbanger/skin-lesion-segmentation-using-segnet"
      ],
      "metadata": {
        "id": "6eDS0wjVaJCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings('ignore')\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "np.random.seed(101)"
      ],
      "metadata": {
        "id": "IeIUK8pcaMDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "numbers = re.compile(r'(\\d+)')\n",
        "def numericalSort(value):\n",
        "    parts = numbers.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts"
      ],
      "metadata": {
        "id": "eads54EQaY6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filelist_trainx = sorted(glob.glob('../input/*/trainx/*.bmp'), key=numericalSort)\n",
        "X_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainx])\n",
        "\n",
        "filelist_trainy = sorted(glob.glob('../input/*/trainy/*.bmp'), key=numericalSort)\n",
        "Y_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainy])"
      ],
      "metadata": {
        "id": "IJ1RSYkTacqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 101)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "3c6ExC-faf_p",
        "outputId": "bdf35597-b2a2-42de-92d1-c896cb910970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-932acb2c94ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac"
      ],
      "metadata": {
        "id": "GDHppXo1ai2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth = 100):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "metadata": {
        "id": "g_Afzm5paoE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(y_true, y_pred):\n",
        "    '''Calculates the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "EyCuESxdarZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    '''Calculates the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "metadata": {
        "id": "eTAS4fEQaugN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    '''Calculates the mean accuracy rate across all predictions for binary\n",
        "    classification problems.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred)))"
      ],
      "metadata": {
        "id": "n_xEUfRXax2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_rotation(x_image, y_image):\n",
        "    rows_x,cols_x, chl_x = x_image.shape\n",
        "    rows_y,cols_y = y_image.shape\n",
        "    rand_num = np.random.randint(-40,40)\n",
        "    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
        "    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
        "    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
        "    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n",
        "    return x_image, y_image.astype('int')\n",
        "\n",
        "def horizontal_flip(x_image, y_image):\n",
        "    x_image = cv2.flip(x_image, 1)\n",
        "    y_image = cv2.flip(y_image.astype('float32'), 1)\n",
        "    return x_image, y_image.astype('int')"
      ],
      "metadata": {
        "id": "lDEitUSYa1FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_augmentation(x_train, y_train):\n",
        "    x_rotat = []\n",
        "    y_rotat = []\n",
        "    x_flip = []\n",
        "    y_flip = []\n",
        "    x_nois = []\n",
        "    for idx in range(len(x_train)):\n",
        "        x,y = random_rotation(x_train[idx], y_train[idx])\n",
        "        x_rotat.append(x)\n",
        "        y_rotat.append(y)\n",
        "\n",
        "        x,y = horizontal_flip(x_train[idx], y_train[idx])\n",
        "        x_flip.append(x)\n",
        "        y_flip.append(y)\n",
        "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
      ],
      "metadata": {
        "id": "dKTdPcW_a5IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_augmentation(x_test, y_test):\n",
        "    x_rotat = []\n",
        "    y_rotat = []\n",
        "    x_flip = []\n",
        "    y_flip = []\n",
        "    x_nois = []\n",
        "    for idx in range(len(x_test)):\n",
        "        x,y = random_rotation(x_test[idx], y_test[idx])\n",
        "        x_rotat.append(x)\n",
        "        y_rotat.append(y)\n",
        "\n",
        "        x,y = horizontal_flip(x_test[idx], y_test[idx])\n",
        "        x_flip.append(x)\n",
        "        y_flip.append(y)\n",
        "\n",
        "    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
      ],
      "metadata": {
        "id": "iB4ny1W7a8wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)\n",
        "x_rotated_t, y_rotated_t, x_flipped_t, y_flipped_t = img_augmentation(x_test, y_test)"
      ],
      "metadata": {
        "id": "t_kLH1n_bAhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For training Set\n",
        "x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
        "y_train_full = np.concatenate([y_train, y_rotated, y_flipped])"
      ],
      "metadata": {
        "id": "kE1Rl1PhbDb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)"
      ],
      "metadata": {
        "id": "_IgsKP9_bHj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of the Training Set   : {}\".format(len(x_train)))\n",
        "print(\"Length of the Test Set       : {}\".format(len(x_test)))\n",
        "print(\"Length of the Validation Set : {}\".format(len(x_val)))"
      ],
      "metadata": {
        "id": "lVM8UPZqbKU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segnet(epochs_num,savename):\n",
        "\n",
        "    # Encoding layer\n",
        "    img_input = Input(shape= (192, 256, 3))\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
        "    x = BatchNormalization(name='bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
        "    x = BatchNormalization(name='bn2')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
        "    x = BatchNormalization(name='bn3')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
        "    x = BatchNormalization(name='bn4')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
        "    x = BatchNormalization(name='bn5')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
        "    x = BatchNormalization(name='bn6')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
        "    x = BatchNormalization(name='bn7')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
        "    x = BatchNormalization(name='bn8')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
        "    x = BatchNormalization(name='bn9')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
        "    x = BatchNormalization(name='bn10')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
        "    x = BatchNormalization(name='bn11')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
        "    x = BatchNormalization(name='bn12')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
        "    x = BatchNormalization(name='bn13')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
        "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
        "    # Decoding Layer\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
        "    x = BatchNormalization(name='bn14')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
        "    x = BatchNormalization(name='bn15')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
        "    x = BatchNormalization(name='bn16')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
        "    x = BatchNormalization(name='bn17')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
        "    x = BatchNormalization(name='bn18')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
        "    x = BatchNormalization(name='bn19')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
        "    x = BatchNormalization(name='bn20')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
        "    x = BatchNormalization(name='bn21')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
        "    x = BatchNormalization(name='bn22')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
        "    x = BatchNormalization(name='bn23')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
        "    x = BatchNormalization(name='bn24')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
        "    x = BatchNormalization(name='bn25')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
        "    x = BatchNormalization(name='bn26')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    pred = Reshape((192,256))(x)\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=pred)\n",
        "\n",
        "    model.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n",
        "                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "    model.summary()\n",
        "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n",
        "\n",
        "    model.save(savename)\n",
        "    return model,hist"
      ],
      "metadata": {
        "id": "ZZMcEYuAbNP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, hist = segnet(1, 'segnet_1_epoch.h5')"
      ],
      "metadata": {
        "id": "N4ZAcokwbWGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding layer\n",
        "img_input = Input(shape= (192, 256, 3))\n",
        "x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
        "x = BatchNormalization(name='bn1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
        "x = BatchNormalization(name='bn2')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
        "x = BatchNormalization(name='bn3')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
        "x = BatchNormalization(name='bn4')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
        "x = BatchNormalization(name='bn5')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
        "x = BatchNormalization(name='bn6')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
        "x = BatchNormalization(name='bn7')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
        "x = BatchNormalization(name='bn8')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
        "x = BatchNormalization(name='bn9')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
        "x = BatchNormalization(name='bn10')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
        "x = BatchNormalization(name='bn11')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
        "x = BatchNormalization(name='bn12')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
        "x = BatchNormalization(name='bn13')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
        "x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
        "# Decoding Layer\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
        "x = BatchNormalization(name='bn14')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
        "x = BatchNormalization(name='bn15')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
        "x = BatchNormalization(name='bn16')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
        "x = BatchNormalization(name='bn17')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
        "x = BatchNormalization(name='bn18')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
        "x = BatchNormalization(name='bn19')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
        "x = BatchNormalization(name='bn20')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
        "x = BatchNormalization(name='bn21')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
        "x = BatchNormalization(name='bn22')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
        "x = BatchNormalization(name='bn23')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
        "x = BatchNormalization(name='bn24')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
        "x = BatchNormalization(name='bn25')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
        "x = BatchNormalization(name='bn26')(x)\n",
        "x = Activation('sigmoid')(x)\n",
        "pred = Reshape((192,256))(x)"
      ],
      "metadata": {
        "id": "XOhmERjfbY-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = Model(inputs=img_input, outputs=pred)\n",
        "\n",
        "model_0.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n",
        "              , metrics=[iou, dice_coef, precision, recall, accuracy])"
      ],
      "metadata": {
        "id": "UwOARkBfb6TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.load_weights('segnet_1_epoch.h5')"
      ],
      "metadata": {
        "id": "4-Rn5RX3b9jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n~~~~~~~~~~~~~~~Stats after 1 epoch~~~~~~~~~~~~~~~~~~~')\n",
        "print('\\n-------------On Train Set--------------------------\\n')\n",
        "res = model_0.evaluate(x_train, y_train, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On Test  Set--------------------------\\n')\n",
        "res = model_0.evaluate(x_test, y_test, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On validation Set---------------------\\n')\n",
        "res = model_0.evaluate(x_val, y_val, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')"
      ],
      "metadata": {
        "id": "10RRCbNxcAkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, hist = segnet(epochs_num= 100, savename= 'segnet_100_epoch.h5')"
      ],
      "metadata": {
        "id": "SoXfAu7zcJ7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Model(inputs=img_input, outputs=pred)\n",
        "model_1.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n",
        "              , metrics=[iou, dice_coef, precision, recall, accuracy])"
      ],
      "metadata": {
        "id": "c2_Q4X7QcOD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.load_weights('segnet_100_epoch.h5')"
      ],
      "metadata": {
        "id": "14yH6EtxcY8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\n",
        "print('\\n-------------On Train Set--------------------------\\n')\n",
        "res = model_1.evaluate(x_train, y_train, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On Test  Set--------------------------\\n')\n",
        "res = model_1.evaluate(x_test, y_test, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On validation Set---------------------\\n')\n",
        "res = model_1.evaluate(x_val, y_val, batch_size= 18)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')"
      ],
      "metadata": {
        "id": "YlWhDGK_cb4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance(img):\n",
        "    sub = (model_1.predict(img.reshape(1,192,256,3))).flatten()\n",
        "\n",
        "    for i in range(len(sub)):\n",
        "        if sub[i] > 0.5:\n",
        "            sub[i] = 1\n",
        "        else:\n",
        "            sub[i] = 0\n",
        "    return sub"
      ],
      "metadata": {
        "id": "4Esnp_Qscf6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.suptitle('Comparing the Prediction after enhancement')\n",
        "plt.subplot(3,2,1)\n",
        "plt.imshow(y_test[21],plt.cm.binary_r)\n",
        "plt.title('Ground Truth')\n",
        "plt.subplot(3,2,2)\n",
        "plt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\n",
        "plt.title('Predicted')\n",
        "plt.subplot(3,2,3)\n",
        "plt.imshow(y_test[47],plt.cm.binary_r)\n",
        "plt.title('Ground Truth')\n",
        "plt.subplot(3,2,4)\n",
        "plt.imshow(enhance(x_test[47]).reshape(192,256), plt.cm.binary_r)\n",
        "plt.title('Predicted')\n",
        "plt.subplot(3,2,5)\n",
        "plt.imshow(y_test[36],plt.cm.binary_r)\n",
        "plt.title('Ground Truth')\n",
        "plt.subplot(3,2,6)\n",
        "plt.imshow(enhance(x_test[36]).reshape(192,256), plt.cm.binary_r)\n",
        "plt.title('Predicted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4nHg8LvVcqvZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}