{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YY8Vjc3BQNA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#import tf.keras.utils.array_to_img\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Layer, Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
        "from keras.layers import ZeroPadding2D, UpSampling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import BatchNormalization\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#from preprocessing.visualize_prepro import shiftedColorMap\n",
        "import itertools\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = sys.argv[1]\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 400, 400\n",
        "# output image dimensions\n",
        "label_rows, label_cols = 400, 400"
      ],
      "metadata": {
        "id": "PP98RcAVBYlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:1'):\n",
        "    # we create two instances with the same arguments\n",
        "    img_data_gen_args = dict(\n",
        "        # featurewise_center=True,\n",
        "        # featurewise_std_normalization=True,\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=90.,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode=\"constant\",\n",
        "        cval=0\n",
        "    )\n",
        "    label_data_gen_args = dict(\n",
        "        rotation_range=90.,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode=\"constant\",\n",
        "        cval=1\n",
        "    )\n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    mask_datagen = ImageDataGenerator(**label_data_gen_args)\n",
        "\n",
        "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
        "    seed = 1\n",
        "    # image_datagen.fit(images, augment=True, seed=seed)\n",
        "    # mask_datagen.fit(masks, augment=True, seed=seed)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        os.path.join(path, '3band/'),\n",
        "        target_size=(img_rows, img_cols),\n",
        "        class_mode=None,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        seed=seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        os.path.join(path, 'labels'),\n",
        "        target_size=(label_rows, label_cols),\n",
        "        class_mode=None,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        color_mode='grayscale',\n",
        "        seed=seed)\n",
        "    train_generator = itertools.izip(image_generator, mask_generator)\n",
        "\n",
        "    kernel = 3\n",
        "    filter_size = 64\n",
        "    pad = 1\n",
        "    pool_size = 2\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Layer(input_shape=(img_rows, img_cols, 3)))\n",
        "    # encoding layers\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(filter_size, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # decoding layers\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(UpSampling2D(size=(pool_size, pool_size)))\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(UpSampling2D(size=(pool_size, pool_size)))\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(UpSampling2D(size=(pool_size, pool_size)))\n",
        "    model.add(ZeroPadding2D(padding=(pad, pad)))\n",
        "    model.add(Convolution2D(filter_size, kernel, kernel, border_mode='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Convolution2D(1, 1, 1, border_mode='valid',))\n",
        "    print (model.output_shape)\n",
        "    model.add(Reshape((label_rows * label_cols,)))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.add(Reshape((label_rows, label_cols, 1)))\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer='rmsprop',\n",
        "                  metrics=['binary_accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=False)\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        samples_per_epoch=1000,\n",
        "        nb_epoch=20,\n",
        "        callbacks=[checkpointer])\n",
        "    model.save('spacenetmodel2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "XnDpsXXhBcIk",
        "outputId": "5ef2852a-47a1-4333-9a74-17e271fd31ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2213efea52a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# mask_datagen.fit(masks, augment=True, seed=seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     image_generator = image_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3band/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f/3band/'"
          ]
        }
      ]
    }
  ]
}