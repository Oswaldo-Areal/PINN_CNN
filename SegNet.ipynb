{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "djRfXape-3YN",
        "outputId": "ee287714-13b3-43b0-9522-4bbb9a6a0500"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d8ed84c69c8e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (/usr/local/lib/python3.10/dist-packages/keras/layers/normalization/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "#from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.core import Activation, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolingWithArgmax2D(Layer):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            pool_size=(2, 2),\n",
        "            strides=(2, 2),\n",
        "            padding='same',\n",
        "            **kwargs):\n",
        "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
        "        self.padding = padding\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        padding = self.padding\n",
        "        pool_size = self.pool_size\n",
        "        strides = self.strides\n",
        "        ksize = [1, pool_size[0], pool_size[1], 1]\n",
        "        padding = padding.upper()\n",
        "        strides = [1, strides[0], strides[1], 1]\n",
        "        output, argmax = tf.nn.max_pool_with_argmax(\n",
        "            inputs,\n",
        "            ksize=ksize,\n",
        "            strides=strides,\n",
        "            padding=padding)\n",
        "\n",
        "        argmax = K.cast(argmax, K.floatx())\n",
        "        return [output, argmax]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        ratio = (1, 2, 2, 1)\n",
        "        output_shape = [\n",
        "            dim // ratio[idx]\n",
        "            if dim is not None else None\n",
        "            for idx, dim in enumerate(input_shape)]\n",
        "        output_shape = tuple(output_shape)\n",
        "        return [output_shape, output_shape]\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return 2 * [None]\n",
        "\n",
        "\n",
        "class MaxUnpooling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), **kwargs):\n",
        "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
        "        self.size = size\n",
        "\n",
        "    def call(self, inputs, output_shape=None):\n",
        "        updates, mask = inputs[0], inputs[1]\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "            mask = K.cast(mask, 'int32')\n",
        "            input_shape = tf.shape(updates, out_type='int32')\n",
        "\n",
        "            if output_shape is None:\n",
        "                output_shape = (\n",
        "                    input_shape[0],\n",
        "                    input_shape[1] * self.size[0],\n",
        "                    input_shape[2] * self.size[1],\n",
        "                    input_shape[3])\n",
        "\n",
        "            ret = tf.scatter_nd(K.expand_dims(K.flatten(mask)),\n",
        "                                  K.flatten(updates),\n",
        "                                  [K.prod(output_shape)])\n",
        "\n",
        "            input_shape = updates.shape\n",
        "            out_shape = [-1,\n",
        "                         input_shape[1] * self.size[0],\n",
        "                         input_shape[2] * self.size[1],\n",
        "                         input_shape[3]]\n",
        "        return K.reshape(ret, out_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        mask_shape = input_shape[1]\n",
        "        return (\n",
        "                mask_shape[0],\n",
        "                mask_shape[1]*self.size[0],\n",
        "                mask_shape[2]*self.size[1],\n",
        "                mask_shape[3]\n",
        "                )"
      ],
      "metadata": {
        "id": "fwpMlmh2_BUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segnet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=\"softmax\"):\n",
        "    # encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
        "    conv_1 = BatchNormalization()(conv_1)\n",
        "    conv_1 = Activation(\"relu\")(conv_1)\n",
        "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
        "    conv_2 = BatchNormalization()(conv_2)\n",
        "    conv_2 = Activation(\"relu\")(conv_2)\n",
        "\n",
        "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
        "\n",
        "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
        "    conv_3 = BatchNormalization()(conv_3)\n",
        "    conv_3 = Activation(\"relu\")(conv_3)\n",
        "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
        "    conv_4 = BatchNormalization()(conv_4)\n",
        "    conv_4 = Activation(\"relu\")(conv_4)\n",
        "\n",
        "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
        "\n",
        "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
        "    conv_5 = BatchNormalization()(conv_5)\n",
        "    conv_5 = Activation(\"relu\")(conv_5)\n",
        "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
        "    conv_6 = BatchNormalization()(conv_6)\n",
        "    conv_6 = Activation(\"relu\")(conv_6)\n",
        "\n",
        "\n",
        "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_6)\n",
        "\n",
        "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
        "    conv_8 = BatchNormalization()(conv_8)\n",
        "    conv_8 = Activation(\"relu\")(conv_8)\n",
        "\n",
        "\n",
        "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_8)\n",
        "\n",
        "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
        "    conv_11 = BatchNormalization()(conv_11)\n",
        "    conv_11 = Activation(\"relu\")(conv_11)\n",
        "\n",
        "\n",
        "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_11)\n",
        "    print(\"Build enceder done..\")\n",
        "\n",
        "    # decoder\n",
        "\n",
        "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
        "\n",
        "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
        "    conv_14 = BatchNormalization()(conv_14)\n",
        "    conv_14 = Activation(\"relu\")(conv_14)\n",
        "\n",
        "\n",
        "    unpool_2 = MaxUnpooling2D(pool_size)([conv_14, mask_4])\n",
        "\n",
        "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
        "    conv_17 = BatchNormalization()(conv_17)\n",
        "    conv_17 = Activation(\"relu\")(conv_17)\n",
        "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_17)\n",
        "    conv_19 = BatchNormalization()(conv_19)\n",
        "    conv_19 = Activation(\"relu\")(conv_19)\n",
        "\n",
        "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
        "\n",
        "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
        "    conv_20 = BatchNormalization()(conv_20)\n",
        "    conv_20 = Activation(\"relu\")(conv_20)\n",
        "    conv_21 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_20)\n",
        "    conv_21 = BatchNormalization()(conv_21)\n",
        "    conv_21 = Activation(\"relu\")(conv_21)\n",
        "\n",
        "    unpool_4 = MaxUnpooling2D(pool_size)([conv_21, mask_2])\n",
        "\n",
        "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
        "    conv_23 = BatchNormalization()(conv_23)\n",
        "    conv_23 = Activation(\"relu\")(conv_23)\n",
        "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
        "    conv_24 = BatchNormalization()(conv_24)\n",
        "    conv_24 = Activation(\"relu\")(conv_24)\n",
        "\n",
        "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
        "\n",
        "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
        "    conv_25 = BatchNormalization()(conv_25)\n",
        "    conv_25 = Activation(\"relu\")(conv_25)\n",
        "\n",
        "    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
        "    conv_26 = BatchNormalization()(conv_26)\n",
        "    conv_26 = Reshape(\n",
        "        (input_shape[0] * input_shape[1], n_labels),\n",
        "        input_shape=(input_shape[0], input_shape[1], n_labels),\n",
        "    )(conv_26)\n",
        "\n",
        "    outputs = Activation(output_mode)(conv_26)\n",
        "    print(\"Build decoder done..\")\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7ZsOMNy8_H87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = segnet((224,224,3), n_labels=5 ,kernel=3, pool_size=(2,2), output_mode=\"softmax\")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)"
      ],
      "metadata": {
        "id": "QZ1Sh-XP_RIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exr_to_jpg(path):\n",
        "    im = imageio.imread(path)\n",
        "    im_gamma_correct = np.clip(np.power(im, 0.45), 0, 1)\n",
        "    im_fixed = Image.fromarray(np.uint8(im_gamma_correct*255))\n",
        "    return im_fixed\n",
        "\n",
        "def category_label(labels, dims, n_labels):\n",
        "    x = np.zeros([dims[0], dims[1], n_labels])\n",
        "    for i in range(dims[0]):\n",
        "        for j in range(dims[1]):\n",
        "            f=int(labels[i,j])\n",
        "            x[i, j, f] = 1\n",
        "    x = x.reshape(dims[0] * dims[1], n_labels)\n",
        "    return x\n",
        "def colorize(img):\n",
        "    w=img.shape[0]\n",
        "    h=img.shape[1]\n",
        "    z=img.shape[2]\n",
        "    l=np.zeros((w,h,3))\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            if img[i,j,0]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,1]==1:\n",
        "                l[i,j,0]=255\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,2]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=255\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,3]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=255\n",
        "            elif img[i,j,4]==1:\n",
        "                l[i,j,0]=238\n",
        "                l[i,j,1]=197\n",
        "                l[i,j,2]=145\n",
        "    return l\n",
        "\n",
        "def class_pixels(img):\n",
        "    w=img.shape[0]\n",
        "    h=img.shape[1]\n",
        "    z=img.shape[2]\n",
        "    l=np.zeros((w,h,z))\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            for f in range(z-1):\n",
        "                if img[i,j,f]==np.max([img[i,j,0],img[i,j,1],img[i,j,2],img[i,j,3],img[i,j,4]]):\n",
        "                    l[i,j,f]=1\n",
        "    return l\n",
        "\n",
        "def data_gen_small(img_dir,mask_dir,depth_dir,liste, batch_size, dims=(224,224), n_labels=5):\n",
        "    while True:\n",
        "        ix = np.random.choice(liste, batch_size)\n",
        "        imgs = []\n",
        "        labels = []\n",
        "        for index in ix:\n",
        "            # images\n",
        "            img_path = img_dir[index]\n",
        "            original_img = exr_to_jpg(img_path)\n",
        "            array_img = img_to_array(original_img)/255\n",
        "            imgs.append(array_img)\n",
        "\n",
        "            # masks\n",
        "            mask_path = mask_dir[index]\n",
        "            original_mask=cv2.imread(mask_path,cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
        "            array_mask = category_label(original_mask[:, :, 0], dims, n_labels)\n",
        "            labels.append(array_mask)\n",
        "\n",
        "        imgs = np.array(imgs)\n",
        "        labels = np.array(labels)\n",
        "        yield imgs, labels"
      ],
      "metadata": {
        "id": "0HrRmTBR_U9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "rgb=[]\n",
        "depth=[]\n",
        "mask=[]\n",
        "node=[]\n",
        "\n",
        "for dirs,subdir,files in os.walk('../input/synthetic-rgbd-images-of-plants/dataset of synthetic rgb-d plants/rgb_map'):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith(\".exr\"):\n",
        "            path_file=dirs+os.sep+file_name\n",
        "            depth_file='../input/synthetic-rgbd-images-of-plants/dataset of synthetic rgb-d plants/depth_map/profondeur_map/'+file_name\n",
        "            mask_file='../input/synthetic-rgbd-images-of-plants/dataset of synthetic rgb-d plants/semantic_map/segmentation2_map/'+file_name\n",
        "            node_file='../input/synthetic-rgbd-images-of-plants/dataset of synthetic rgb-d plants/nodes_map/internoeuds_map/'+file_name\n",
        "            rgb.append(path_file)\n",
        "            depth.append(depth_file)\n",
        "            mask.append(mask_file)\n",
        "            node.append(node_file)\n",
        "\n",
        "liste=np.arange(1,10000)\n",
        "np.random.shuffle(liste)\n",
        "\n",
        "train_list=liste[0:8000]\n",
        "val_list=liste[8000:9000]\n",
        "test_list=liste[9000:9999]\n",
        "\n",
        "\n",
        "train_gen = data_gen_small(rgb\n",
        ",mask,depth,liste=train_list,batch_size=16,dims=(224,224),n_labels=5)\n",
        "val_gen=data_gen_small(rgb\n",
        ",mask,depth,liste=val_list,batch_size=16,dims=(224,224),n_labels=5)\n",
        "test_gen = data_gen_small(rgb\n",
        ",mask,depth,liste=test_list,batch_size=1,dims=(224,224),n_labels=5)"
      ],
      "metadata": {
        "id": "2beH-HFg_eL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "\n",
        "    epsilon=1e-6\n",
        "    axes = tuple(range(1, len(y_pred.shape)-1))\n",
        "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
        "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
        "\n",
        "    return K.mean((numerator + epsilon) / (denominator + epsilon))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "mZKALPH4_nFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=dice_coef_loss, optimizer='adam', metrics=[\"accuracy\",dice_coef])"
      ],
      "metadata": {
        "id": "dEL4a8gW_qiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(\n",
        "        train_gen,\n",
        "        steps_per_epoch=500,\n",
        "        epochs=50,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=62\n",
        "    )"
      ],
      "metadata": {
        "id": "AbAa0j1z_tmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('../input/pre-model-2/only_rgb_dice.hdf5')"
      ],
      "metadata": {
        "id": "03uHZ17X_wo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# plotting of training and validation loss curves\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sx3EbZ5N_04Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h=0\n",
        "for i in test_list:\n",
        "    if h<50:\n",
        "\n",
        "        img_path = rgb[i]\n",
        "        original_img = exr_to_jpg(img_path)\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(15,15))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(original_img)\n",
        "        array_img=img_to_array(original_img)/255\n",
        "\n",
        "        array_img2 = np.reshape(array_img, (1,224,224,3))\n",
        "        y_pred=model.predict(array_img2)\n",
        "        y_pred=np.reshape(y_pred,(224,224,6))\n",
        "        c=class_pixels(y_pred)\n",
        "        o=colorize(c)\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(o)\n",
        "        plt.show()\n",
        "        h+=1\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "-QVV9giE_4kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vEVBIBXR_9XI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}